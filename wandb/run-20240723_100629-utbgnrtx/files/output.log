number of parameters: 0.00M
num decayed parameter tensors: 14, with 1,686 parameters
num non-decayed parameter tensors: 7, with 42 parameters
using fused AdamW: False
Epoch 1/100, Avg Training Loss: 2.0832703709602356
Epoch 2/100, Avg Training Loss: 1.8088047623634338
Epoch 3/100, Avg Training Loss: 1.533732569217682
Epoch 4/100, Avg Training Loss: 1.301856315135956
Epoch 5/100, Avg Training Loss: 1.1175200581550597
Epoch 6/100, Avg Training Loss: 0.9766218721866607
Epoch 7/100, Avg Training Loss: 0.8715685367584228
Epoch 8/100, Avg Training Loss: 0.7799069464206696
Epoch 9/100, Avg Training Loss: 0.6895681977272033
Epoch 10/100, Avg Training Loss: 0.6470346450805664
Epoch 11/100, Avg Training Loss: 0.6176820695400238
Epoch 12/100, Avg Training Loss: 0.5663610994815826
Epoch 13/100, Avg Training Loss: 0.5200436979532241
Epoch 14/100, Avg Training Loss: 0.4653448790311813
Epoch 15/100, Avg Training Loss: 0.43074272871017455
Epoch 16/100, Avg Training Loss: 0.36770893931388854
Epoch 17/100, Avg Training Loss: 0.356146565079689
Epoch 18/100, Avg Training Loss: 0.30084114372730253
Epoch 19/100, Avg Training Loss: 0.26900606602430344
Epoch 20/100, Avg Training Loss: 0.25827026516199114
Epoch 21/100, Avg Training Loss: 0.23972222506999968
Epoch 22/100, Avg Training Loss: 0.20038294792175293
Epoch 23/100, Avg Training Loss: 0.17775778472423553
Epoch 24/100, Avg Training Loss: 0.16176419481635093
Epoch 25/100, Avg Training Loss: 0.14234093576669693
Epoch 26/100, Avg Training Loss: 0.10028205588459968
Epoch 27/100, Avg Training Loss: 0.0907444141805172
Epoch 28/100, Avg Training Loss: 0.09665698707103729
Epoch 29/100, Avg Training Loss: 0.08810239210724831
Epoch 30/100, Avg Training Loss: 0.05521244127303362
Epoch 31/100, Avg Training Loss: 0.04560897890478373
Epoch 32/100, Avg Training Loss: 0.037224181741476056
Epoch 33/100, Avg Training Loss: 0.05307480366900563
Epoch 34/100, Avg Training Loss: 0.0427259910851717
Epoch 35/100, Avg Training Loss: 0.06071151662617922
Epoch 36/100, Avg Training Loss: 0.07495416905730963
Epoch 37/100, Avg Training Loss: 0.04193061133846641
Epoch 38/100, Avg Training Loss: 0.026073544286191463
Epoch 39/100, Avg Training Loss: 0.028281856421381237
Epoch 40/100, Avg Training Loss: 0.013513355422765017
Epoch 41/100, Avg Training Loss: 0.015267451386898756
Epoch 42/100, Avg Training Loss: 0.009737520199269056
Epoch 43/100, Avg Training Loss: 0.005797961028292775
Epoch 44/100, Avg Training Loss: 0.004252852825447917
Epoch 45/100, Avg Training Loss: 0.003700042492710054
Epoch 46/100, Avg Training Loss: 0.004925291240215302
Epoch 47/100, Avg Training Loss: 0.01812095968052745
Epoch 48/100, Avg Training Loss: 0.020648906310088932
Epoch 49/100, Avg Training Loss: 0.11088297329843044
Epoch 50/100, Avg Training Loss: 0.05548297669738531
Epoch 51/100, Avg Training Loss: 0.019073878368362784
Epoch 52/100, Avg Training Loss: 0.006844037119299174
Epoch 53/100, Avg Training Loss: 0.0061366288922727105
Epoch 54/100, Avg Training Loss: 0.0034410580759868027
Epoch 55/100, Avg Training Loss: 0.002636760240420699
Epoch 56/100, Avg Training Loss: 0.002288210205733776
Epoch 57/100, Avg Training Loss: 0.0022331718588247894
Epoch 58/100, Avg Training Loss: 0.0017690791632048787
Epoch 59/100, Avg Training Loss: 0.001699555735103786
Epoch 60/100, Avg Training Loss: 0.001956256409175694
Epoch 61/100, Avg Training Loss: 0.004976213455665857
Epoch 62/100, Avg Training Loss: 0.03285861088661477
Epoch 63/100, Avg Training Loss: 0.006998772267252207
Epoch 64/100, Avg Training Loss: 0.0038987965905107557
Epoch 65/100, Avg Training Loss: 0.002118406514637172
Epoch 66/100, Avg Training Loss: 0.004005999909713865
Epoch 67/100, Avg Training Loss: 0.005368971265852451
Epoch 68/100, Avg Training Loss: 0.0032690506894141437
Epoch 69/100, Avg Training Loss: 0.01530910236760974
Epoch 70/100, Avg Training Loss: 0.003130302170757204
Epoch 71/100, Avg Training Loss: 0.0026051323919091375
Epoch 72/100, Avg Training Loss: 0.019448511069640517
Epoch 73/100, Avg Training Loss: 0.00283530248561874
Epoch 74/100, Avg Training Loss: 0.001986826816573739
Epoch 75/100, Avg Training Loss: 0.0017033592564985156
Epoch 76/100, Avg Training Loss: 0.001311698171775788
Epoch 77/100, Avg Training Loss: 0.001246233918936923
Epoch 78/100, Avg Training Loss: 0.00114404444466345
Epoch 79/100, Avg Training Loss: 0.0008373155782464891
Epoch 80/100, Avg Training Loss: 0.0006958764686714857
Epoch 81/100, Avg Training Loss: 0.0005870707682333887
Epoch 82/100, Avg Training Loss: 0.0005048453371273353
Epoch 83/100, Avg Training Loss: 0.00043904707417823373
Epoch 84/100, Avg Training Loss: 0.0003943111776607111
Epoch 85/100, Avg Training Loss: 0.0003392931364942342
Epoch 86/100, Avg Training Loss: 0.0002948132198071107
Epoch 87/100, Avg Training Loss: 0.000258186599239707
Epoch 88/100, Avg Training Loss: 0.0001925007876707241
Epoch 89/100, Avg Training Loss: 0.00016389976080972702
Epoch 90/100, Avg Training Loss: 0.00012839217597502284
Epoch 91/100, Avg Training Loss: 0.0001121690082072746
Epoch 92/100, Avg Training Loss: 8.706467560841702e-05
Epoch 93/100, Avg Training Loss: 6.956576180527918e-05
Epoch 94/100, Avg Training Loss: 5.752763354394119e-05
Epoch 95/100, Avg Training Loss: 4.3980223199469035e-05
Epoch 96/100, Avg Training Loss: 3.9275959716178475e-05
Epoch 97/100, Avg Training Loss: 4.106880442122929e-05
Epoch 98/100, Avg Training Loss: 0.13534954112437844
Epoch 99/100, Avg Training Loss: 0.10294817453250289
Epoch 100/100, Avg Training Loss: 0.03992285239510238
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")