number of parameters: 0.04M
num decayed parameter tensors: 10, with 40,760 parameters
num non-decayed parameter tensors: 5, with 200 parameters
using fused AdamW: False
Epoch 1/10, Avg Training Loss: 0.9306535923480987
Epoch 2/10, Avg Training Loss: 0.2904430191963911
Epoch 3/10, Avg Training Loss: 0.06459901049733162
Epoch 4/10, Avg Training Loss: 0.00948582036420703
Epoch 5/10, Avg Training Loss: 0.001366621475899592
Epoch 6/10, Avg Training Loss: 0.00013732710336626042
Epoch 7/10, Avg Training Loss: 0.00036983590231329797
Epoch 8/10, Avg Training Loss: 0.055819175794167675
Epoch 9/10, Avg Training Loss: 0.00010068986397527623
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Epoch 10/10, Avg Training Loss: 1.4033927936907275e-05
attention_weights shape: torch.Size([1, 2, 13, 13])
attention_weights shape: torch.Size([1, 2, 13, 13])