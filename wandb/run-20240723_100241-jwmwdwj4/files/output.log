number of parameters: 0.00M
num decayed parameter tensors: 10, with 1,242 parameters
num non-decayed parameter tensors: 5, with 30 parameters
using fused AdamW: False
Epoch 1/80, Avg Training Loss: 1.4029262840747834
Epoch 2/80, Avg Training Loss: 0.6654325067996979
Epoch 3/80, Avg Training Loss: 0.6476847231388092
Epoch 4/80, Avg Training Loss: 0.6091022074222565
Epoch 5/80, Avg Training Loss: 0.6175424814224243
Epoch 6/80, Avg Training Loss: 0.5800702571868896
Epoch 7/80, Avg Training Loss: 0.6009994864463806
Epoch 8/80, Avg Training Loss: 0.6258412301540375
Epoch 9/80, Avg Training Loss: 0.533895680308342
Epoch 10/80, Avg Training Loss: 0.47914873659610746
Epoch 11/80, Avg Training Loss: 0.5159992516040802
Epoch 12/80, Avg Training Loss: 0.5077270835638046
Epoch 13/80, Avg Training Loss: 0.5203662812709808
Epoch 14/80, Avg Training Loss: 0.4644527167081833
Epoch 15/80, Avg Training Loss: 0.5106936782598496
Epoch 16/80, Avg Training Loss: 0.5847422301769256
Epoch 17/80, Avg Training Loss: 0.5346372604370118
Epoch 18/80, Avg Training Loss: 0.47918263971805575
Epoch 19/80, Avg Training Loss: 0.5009291648864747
Epoch 20/80, Avg Training Loss: 0.45295309126377103
Epoch 21/80, Avg Training Loss: 0.3936017483472824
Epoch 22/80, Avg Training Loss: 0.30843709260225294
Epoch 23/80, Avg Training Loss: 0.4793132424354553
Epoch 24/80, Avg Training Loss: 0.33738344013690946
Epoch 25/80, Avg Training Loss: 0.27432548999786377
Epoch 26/80, Avg Training Loss: 0.2622338026762009
Epoch 27/80, Avg Training Loss: 0.26410879492759703
Epoch 28/80, Avg Training Loss: 0.29809251576662066
Epoch 29/80, Avg Training Loss: 0.34632008224725724
Epoch 30/80, Avg Training Loss: 0.1659620463848114
Epoch 31/80, Avg Training Loss: 0.11765040755271912
Epoch 32/80, Avg Training Loss: 0.1206100933253765
Epoch 33/80, Avg Training Loss: 0.3576913133263588
Epoch 34/80, Avg Training Loss: 0.3321322575211525
Epoch 35/80, Avg Training Loss: 0.3405294120311737
Epoch 36/80, Avg Training Loss: 0.38115345537662504
Epoch 37/80, Avg Training Loss: 0.398466357588768
Epoch 38/80, Avg Training Loss: 0.3340123951435089
Epoch 39/80, Avg Training Loss: 0.3333839625120163
Epoch 40/80, Avg Training Loss: 0.30729986280202864
Epoch 41/80, Avg Training Loss: 0.25808663964271544
Epoch 42/80, Avg Training Loss: 0.2870773017406464
Epoch 43/80, Avg Training Loss: 0.47736976444721224
Epoch 44/80, Avg Training Loss: 0.6525722593069077
Epoch 45/80, Avg Training Loss: 0.5076772987842559
Epoch 46/80, Avg Training Loss: 0.2934620127081871
Epoch 47/80, Avg Training Loss: 0.23950797468423843
Epoch 48/80, Avg Training Loss: 0.24022959023714066
Epoch 49/80, Avg Training Loss: 0.14046868830919265
Epoch 50/80, Avg Training Loss: 0.11173607707023621
Epoch 51/80, Avg Training Loss: 0.27181106358766555
Epoch 52/80, Avg Training Loss: 0.253215292096138
Epoch 53/80, Avg Training Loss: 0.14986191615462302
Epoch 54/80, Avg Training Loss: 0.15261137187480928
Epoch 55/80, Avg Training Loss: 0.2776248440146446
Epoch 56/80, Avg Training Loss: 0.3247838571667671
Epoch 57/80, Avg Training Loss: 0.32463524788618087
Epoch 58/80, Avg Training Loss: 0.27658703178167343
Epoch 59/80, Avg Training Loss: 0.20463810116052628
Epoch 60/80, Avg Training Loss: 0.27191044837236406
Epoch 61/80, Avg Training Loss: 0.2053895801305771
Epoch 62/80, Avg Training Loss: 0.17503308728337288
Epoch 63/80, Avg Training Loss: 0.22462962120771407
Epoch 64/80, Avg Training Loss: 0.2237257555127144
Epoch 65/80, Avg Training Loss: 0.20745199173688889
Epoch 66/80, Avg Training Loss: 0.2009899139404297
Epoch 67/80, Avg Training Loss: 0.12645112536847591
Epoch 68/80, Avg Training Loss: 0.08887864723801613
Epoch 69/80, Avg Training Loss: 0.07035096846520901
Epoch 70/80, Avg Training Loss: 0.13680871948599815
Epoch 71/80, Avg Training Loss: 0.18417910784482955
Epoch 72/80, Avg Training Loss: 0.28962785601615904
Epoch 73/80, Avg Training Loss: 0.288798925280571
Epoch 74/80, Avg Training Loss: 0.2940365016460419
Epoch 75/80, Avg Training Loss: 0.26080562770366666
Epoch 76/80, Avg Training Loss: 0.31815527826547624
Epoch 77/80, Avg Training Loss: 0.29813858270645144
Epoch 78/80, Avg Training Loss: 0.2682666927576065
Epoch 79/80, Avg Training Loss: 0.20396228954195977
Epoch 80/80, Avg Training Loss: 0.14646145105361938
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")