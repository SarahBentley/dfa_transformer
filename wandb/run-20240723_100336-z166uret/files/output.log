number of parameters: 0.00M
num decayed parameter tensors: 10, with 1,242 parameters
num non-decayed parameter tensors: 5, with 30 parameters
using fused AdamW: False
Epoch 1/100, Avg Training Loss: 2.0499961137771607
Epoch 2/100, Avg Training Loss: 1.7293271541595459
Epoch 3/100, Avg Training Loss: 1.448526918888092
Epoch 4/100, Avg Training Loss: 1.2341760039329528
Epoch 5/100, Avg Training Loss: 1.0876940369606019
Epoch 6/100, Avg Training Loss: 0.9694438397884368
Epoch 7/100, Avg Training Loss: 0.904679149389267
Epoch 8/100, Avg Training Loss: 0.8342715501785278
Epoch 9/100, Avg Training Loss: 0.79325732588768
Epoch 10/100, Avg Training Loss: 0.7485044479370118
Epoch 11/100, Avg Training Loss: 0.7373986542224884
Epoch 12/100, Avg Training Loss: 0.7000528872013092
Epoch 13/100, Avg Training Loss: 0.6657590687274932
Epoch 14/100, Avg Training Loss: 0.6184904277324677
Epoch 15/100, Avg Training Loss: 0.6000730335712433
Epoch 16/100, Avg Training Loss: 0.5808897078037262
Epoch 17/100, Avg Training Loss: 0.6215599477291107
Epoch 18/100, Avg Training Loss: 0.608368706703186
Epoch 19/100, Avg Training Loss: 0.6004105627536773
Epoch 20/100, Avg Training Loss: 0.5858220458030701
Epoch 21/100, Avg Training Loss: 0.5828115940093994
Epoch 22/100, Avg Training Loss: 0.5953716099262237
Epoch 23/100, Avg Training Loss: 0.5596660375595093
Epoch 24/100, Avg Training Loss: 0.5507920742034912
Epoch 25/100, Avg Training Loss: 0.5602479815483093
Epoch 26/100, Avg Training Loss: 0.5355512738227844
Epoch 27/100, Avg Training Loss: 0.5289910823106766
Epoch 28/100, Avg Training Loss: 0.5140531241893769
Epoch 29/100, Avg Training Loss: 0.48524021804332734
Epoch 30/100, Avg Training Loss: 0.46428434252738954
Epoch 31/100, Avg Training Loss: 0.44257923662662507
Epoch 32/100, Avg Training Loss: 0.4081690311431885
Epoch 33/100, Avg Training Loss: 0.3818166971206665
Epoch 34/100, Avg Training Loss: 0.39410664737224577
Epoch 35/100, Avg Training Loss: 0.36867467164993284
Epoch 36/100, Avg Training Loss: 0.3693655043840408
Epoch 37/100, Avg Training Loss: 0.32872274369001386
Epoch 38/100, Avg Training Loss: 0.3322915703058243
Epoch 39/100, Avg Training Loss: 0.2984889954328537
Epoch 40/100, Avg Training Loss: 0.2721359834074974
Epoch 41/100, Avg Training Loss: 0.2788221165537834
Epoch 42/100, Avg Training Loss: 0.2574048027396202
Epoch 43/100, Avg Training Loss: 0.21954041123390197
Epoch 44/100, Avg Training Loss: 0.22835374921560286
Epoch 45/100, Avg Training Loss: 0.22419328838586808
Epoch 46/100, Avg Training Loss: 0.21000395119190216
Epoch 47/100, Avg Training Loss: 0.1673065811395645
Epoch 48/100, Avg Training Loss: 0.22607382982969285
Epoch 49/100, Avg Training Loss: 0.1680948629975319
Epoch 50/100, Avg Training Loss: 0.14299004673957824
Epoch 51/100, Avg Training Loss: 0.14153019562363625
Epoch 52/100, Avg Training Loss: 0.11652153879404067
Epoch 53/100, Avg Training Loss: 0.11333792842924595
Epoch 54/100, Avg Training Loss: 0.09354643486440181
Epoch 55/100, Avg Training Loss: 0.1764677118510008
Epoch 56/100, Avg Training Loss: 0.1369528878480196
Epoch 57/100, Avg Training Loss: 0.10418905317783356
Epoch 58/100, Avg Training Loss: 0.07503931820392609
Epoch 59/100, Avg Training Loss: 0.05286627504974604
Epoch 60/100, Avg Training Loss: 0.05925098266452551
Epoch 61/100, Avg Training Loss: 0.054194350726902485
Epoch 62/100, Avg Training Loss: 0.0830551128834486
Epoch 63/100, Avg Training Loss: 0.046467177011072634
Epoch 64/100, Avg Training Loss: 0.10009901896119118
Epoch 65/100, Avg Training Loss: 0.06604347769171
Epoch 66/100, Avg Training Loss: 0.03713423879817128
Epoch 67/100, Avg Training Loss: 0.03934853002429008
Epoch 68/100, Avg Training Loss: 0.028296033013612033
Epoch 69/100, Avg Training Loss: 0.06817011460661888
Epoch 70/100, Avg Training Loss: 0.04731116201728582
Epoch 71/100, Avg Training Loss: 0.034749573655426504
Epoch 72/100, Avg Training Loss: 0.04606252438388765
Epoch 73/100, Avg Training Loss: 0.020461731916293503
Epoch 74/100, Avg Training Loss: 0.010807004990056157
Epoch 75/100, Avg Training Loss: 0.0165904242079705
Epoch 76/100, Avg Training Loss: 0.040707230055704716
Epoch 77/100, Avg Training Loss: 0.10427993573248387
Epoch 78/100, Avg Training Loss: 0.08118798974901438
Epoch 79/100, Avg Training Loss: 0.03784537459723651
Epoch 80/100, Avg Training Loss: 0.029354012198746206
Epoch 81/100, Avg Training Loss: 0.02668743673712015
Epoch 82/100, Avg Training Loss: 0.03143212446011603
Epoch 83/100, Avg Training Loss: 0.042510449420660734
Epoch 84/100, Avg Training Loss: 0.03623088607564569
Epoch 85/100, Avg Training Loss: 0.023797797970473766
Epoch 86/100, Avg Training Loss: 0.02697707791812718
Epoch 87/100, Avg Training Loss: 0.09609682522714139
Epoch 88/100, Avg Training Loss: 0.0497931657359004
Epoch 89/100, Avg Training Loss: 0.04877593228593469
Epoch 90/100, Avg Training Loss: 0.02216875709127635
Epoch 91/100, Avg Training Loss: 0.010040667816065251
Epoch 92/100, Avg Training Loss: 0.004880541353486478
Epoch 93/100, Avg Training Loss: 0.009686591743957251
Epoch 94/100, Avg Training Loss: 0.006371135823428631
Epoch 95/100, Avg Training Loss: 0.004958081198856235
Epoch 96/100, Avg Training Loss: 0.006218932871706784
Epoch 97/100, Avg Training Loss: 0.007878936716588214
Epoch 98/100, Avg Training Loss: 0.004044368205359206
Epoch 99/100, Avg Training Loss: 0.002801017358433455
Epoch 100/100, Avg Training Loss: 0.038916555012110624
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")